{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@author: Madhumitha Sakthi, Maansi Desai\n",
    "\n",
    "This code processes the .fif EEG files and concatenates each sentence from subjects and saves them as .npy file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import mne # For loading EEG data\n",
    "import numpy as np\n",
    "from praatio import tgio # For importing textgrids with word level transcriptions\n",
    "import glob \n",
    "import os\n",
    "import json\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import decomposition\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define subject\n",
    "subjects = ['MT0001','MT0002','MT0003','MT0004','MT0005','MT0006', 'MT0008','MT0009', 'MT0010', 'MT0011', 'MT0012', 'MT0013', 'MT0014', 'MT0015', 'MT0016', 'MT0017']\n",
    "\n",
    "data_dir = 'path/to/original/files'  #.fif files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_raw_EEG(subject, data_dir):\n",
    "    '''\n",
    "    Load the preprocessed EEG (post-ICA), removing bad time points if they exist\n",
    "    Input : \n",
    "        subject [str] : the subject ID (e.g. 'MT0001')\n",
    "        data_dir [str] : the path to your data\n",
    "    Output : \n",
    "        raw [mne Raw object] : the data structure containing the EEG for this participant\n",
    "    '''\n",
    "    eeg_file = '%s/%s_postICA_rejected.fif'%(data_dir, subject)\n",
    "    raw = mne.io.read_raw_fif(eeg_file, preload=True)\n",
    "    \n",
    "\n",
    "    # Print which are the bad channels, but don't get rid of them yet...\n",
    "    raw.pick_types(eeg=True, meg=False, exclude=[])\n",
    "    bad_chans = raw.info['bads']\n",
    "    print(\"Bad channels are: \")\n",
    "    print(bad_chans)\n",
    "\n",
    "    # Get onset and duration of the bad segments in samples\n",
    "    bad_time_onsets = raw.annotations.onset * raw.info['sfreq']\n",
    "    bad_time_durs = raw.annotations.duration * raw.info['sfreq']\n",
    "\n",
    "    print(raw._data.shape)\n",
    "\n",
    "    # Set the bad time points to zero\n",
    "    for bad_idx, bad_time in enumerate(bad_time_onsets):\n",
    "        raw._data[:,np.int(bad_time):np.int(bad_time+bad_time_durs[bad_idx])] = 0\n",
    "    \n",
    "    return raw\n",
    "\n",
    "# Load event file and get times of TIMIT sentences or MTs\n",
    "def load_event_file(subject, data_dir, fs=128, event_file_name='TIMIT'):\n",
    "    '''\n",
    "    Get the TIMIT or MovieTrailers event file with start and stop times relative to the EEG start time for a \n",
    "    particular subject. This event file has one row per TIMIT sentence or one row per MovieTrailer, depending\n",
    "    on which stimulus is chosen.\n",
    "    Inputs:\n",
    "        subject [str] : subject ID (e.g. 'MT0001')\n",
    "        data_dir [str] : path to your data and event files\n",
    "        fs [int] : the sampling frequency for returning the samples\n",
    "        event_file_name [str] : 'TIMIT' or 'MovieTrailers' -- which event file to load\n",
    "    Output:\n",
    "        evs : the offset and onset samples (assuming [fs] sampling frequency)\n",
    "        wav_id : the name of the .wav that corresponds to ev\n",
    "    '''\n",
    "    if event_file_name=='TIMIT':\n",
    "        event_file = '%s/%s_TIMIT_all_events.txt'%(data_dir, subject) #timit\n",
    "        \n",
    "    elif event_file_name=='MOVIE':\n",
    "        event_file = '%s/%s_MovieTrailers_events.txt'%(data_dir, subject) #movie trailer\n",
    "    \n",
    "    else:\n",
    "        print('Input is unrecognizable.')\n",
    "   \n",
    "    # Load the columns with the times    \n",
    "    evs = np.loadtxt(event_file, dtype='f', usecols = (0, 1, 2))\n",
    "    evs[:,:2] = evs[:,:2]*fs #128 is the downsampled frequency from EEG data\n",
    "    evs = evs.astype(np.int) #this takes into account onset and offset times\n",
    "    wav_id = np.loadtxt(event_file, dtype='<U', usecols = 3) #name of .wav filename\n",
    "    \n",
    "    return evs, wav_id\n",
    "\n",
    "\n",
    "#function to epoch your data\n",
    "def get_event_epoch(raw, evs, event_id, wav_id, bef_aft=[-0.5,0.5], baseline = None, reject_by_annotation=False):\n",
    "\n",
    "    '''\n",
    "    Epoch preprocessed EEG (post-ICA). Will epoch based on length of TIMIT sentence specified in event file\n",
    "    Input : \n",
    "        raw [mne Raw object] : created from load_raw_EEG for given participant\n",
    "        evs [numpy array] : the path to your data with all event onset information from textfiles. Also contains event_id in last column\n",
    "        event_id [int]: last column in evs \n",
    "        bef_aft: hard coded to give epochs of neural data 0.5 seconds before and after\n",
    "    Output : \n",
    "        raw [mne Raw object] : the data structure containing the EEG for this participant\n",
    "    '''\n",
    "    \n",
    "    # Get duration information\n",
    "    max_samp_dur = np.max(evs[(np.where(evs[:,2] == event_id)),1]-evs[(np.where(evs[:,2] == event_id)),0])\n",
    "    trial_dur = max_samp_dur/raw.info['sfreq']\n",
    "    \n",
    "    epochs = mne.Epochs(raw, evs, event_id=[event_id], tmin=bef_aft[0], tmax=trial_dur+bef_aft[1], baseline=baseline,\n",
    "                        reject_by_annotation=reject_by_annotation)\n",
    "    ep = epochs.get_data()\n",
    "    times = epochs.times\n",
    "    wav_title = wav_id[np.where(evs[:,2] == event_id)]\n",
    "        \n",
    "    return ep, times, wav_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterate through each subject and save data\n",
    "f = open('start_time.json',)  #loads the start of word onset for each movie trailer\n",
    "data_time = json.load(f)\n",
    "print(data_time)\n",
    "for subject in subjects:\n",
    "    sub_dir = data_dir+'/'+ subject\n",
    "    print(\"sub_dir:\", sub_dir)\n",
    "    raw = load_raw_EEG(subject, sub_dir)\n",
    "    raw.interpolate_bads() # Interpolate the bad channels \n",
    "    raw.plot_psd()\n",
    "\n",
    "    ch_names = raw.info['ch_names']\n",
    "\n",
    "    # Get the sentence event times.\n",
    "    # evs contains the start sample, stop sample, and unique number identifying the sentence\n",
    "    # These unique names can be matched up to specific wav files in Stimuli/wavs and Stimuli/Textgrids\n",
    "    # with wav_id\n",
    "    \n",
    "    #load timit data\n",
    "    evs_timit, wav_id_timit = load_event_file(subject, sub_dir, fs=128, event_file_name='TIMIT')\n",
    "    \n",
    "    #load movie data\n",
    "    evs_movie, wav_id_movie = load_event_file(subject, sub_dir, fs=128, event_file_name='MOVIE')\n",
    "    \n",
    "    timit_total = 0\n",
    "    movie_total = 0\n",
    "    timit_filename = data_dir + '/EEG_classifier/'+ subject + 'timit.npy'\n",
    "    movie_filename = data_dir + '/EEG_classifier/'+ subject + 'movie.npy'\n",
    "    \n",
    "    #concatenate timit sentences\n",
    "    event_ids = evs_timit[:,2]\n",
    "    #print(event_ids.shape)\n",
    "    event_ids = np.unique(event_ids) #extract unique sentences from event_files\n",
    "    #print(event_ids)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    #print(event_ids.shape[0])\n",
    "    for x in range(event_ids.shape[0]):\n",
    "        event_id = event_ids[x]\n",
    "        \n",
    "        #print(\"event id:\", event_id)\n",
    "        ep, times, wav_title = get_event_epoch(raw, evs_timit, event_id, wav_id_timit, bef_aft=[-0.5,1], baseline = (None, 0), reject_by_annotation=False)\n",
    "        #print(\"ep shape:\", ep.shape)\n",
    "        if ep.shape[0] >= 1:\n",
    "            ep = ep[[0]] #load the first sentence EEG to avoid repetition \n",
    "            ep = ep.reshape(ep.shape[1], ep.shape[2])\n",
    "            #average length of each timit sentence is 3s and at 128 Hz that is 350 samples\n",
    "            if ep.shape[1] < 350:\n",
    "                ep_pad = np.zeros((ep.shape[0], 350))\n",
    "                ep_pad[:,:ep.shape[1]] = ep\n",
    "            else:\n",
    "                ep_pad = ep[:,:350]\n",
    "            \n",
    "            \n",
    "            timit_total = timit_total + 1\n",
    "\n",
    "            if (x == 0):\n",
    "                timit_array = ep_pad.T   \n",
    "            else:\n",
    "                timit_array = np.dstack((timit_array,ep_pad.T)) #stack each EEG\\\n",
    "                #for different sentences in the first dimension\n",
    "                \n",
    "    \n",
    "    print(\"individual timit events :\", timit_total)\n",
    "    print(timit_array.T.shape)\n",
    "    np.save(timit_filename, timit_array.T)\n",
    "    \n",
    "    #concatenate movie sentences\n",
    "    event_ids = evs_movie[:,2]\n",
    "    print(event_ids.shape)\n",
    "    event_ids = np.unique(event_ids) #extract unique sentences from event_files\n",
    "    print(event_ids)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    #print(event_ids.shape[0])\n",
    "    for x in range(event_ids.shape[0]):\n",
    "        event_id = event_ids[x]\n",
    "        \n",
    "        #print(\"event id:\", event_id)\n",
    "        ep, times, wav_title = get_event_epoch(raw, evs_movie, event_id, wav_id_movie, bef_aft=[-0.5,1], baseline = (None, 0), reject_by_annotation=False)\n",
    "        time = data_time[wav_title[0][:-4]] #start time of movie trailers data\n",
    "        if ep.shape[0] >= 1:\n",
    "            ep = ep[[0]]\n",
    "            ep = ep.reshape(ep.shape[1], ep.shape[2])\n",
    "            print(ep.shape)\n",
    "            ep = ep[:,int(time*128):]\n",
    "            print(ep.shape)\n",
    "            #removing the silences from the beginning\n",
    "            movie_total = movie_total + 1\n",
    "            num = int(ep.shape[1]/350)\n",
    "            \n",
    "            for samples in range(num):\n",
    "            \n",
    "                ep_pad = ep[:,int(350*samples):int(350*(samples+1))]\n",
    "                if (x == 0):\n",
    "                    movie_array = ep_pad.T\n",
    "                    #print(movie_array.shape)\n",
    "                else:\n",
    "                    #print(ep_pad.T.shape)\n",
    "                    movie_array = np.dstack((movie_array,ep_pad.T))\n",
    "                        \n",
    "    print(\"individual movie events :\", movie_total)\n",
    "    print(movie_array.T.shape)\n",
    "    np.save(movie_filename, movie_array.T)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
