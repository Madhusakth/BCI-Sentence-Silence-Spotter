{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "Av-model-classifier-model.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oz3VkEhEEJwA"
      },
      "source": [
        "**Audio vs. Audio-Visual Model**\n",
        "\n",
        "The code below trains a Audio vs. Audio-visual classfier model on all the 16 subject data. There are four different RNN models and a Gaussian Bayes model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LF7heH0r79N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca436b7d-cde0-4a39-d82f-457e0d264896"
      },
      "source": [
        "#use these lines to mount google drive for free access to google colab gpu\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sF71VFwDsFJz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e25389ac-1db5-4f3b-be5a-4a8f1caebe48"
      },
      "source": [
        "!pip install mne"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mne\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4d/0e/6448521738d3357c205795fd5846d023bd7935bb83ba93a1ba0f7124205e/mne-0.21.2-py3-none-any.whl (6.8MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8MB 5.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from mne) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.17.1 in /usr/local/lib/python3.6/dist-packages (from mne) (1.4.1)\n",
            "Installing collected packages: mne\n",
            "Successfully installed mne-0.21.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caUb7AsSrx9I"
      },
      "source": [
        "#import packages\n",
        "import mne # For loading EEG data\n",
        "import numpy as np\n",
        "#from praatio import tgio # For importing textgrids with word level transcriptions\n",
        "import glob \n",
        "import os\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn import decomposition\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "%matplotlib inline\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rClMSb0Trx9X"
      },
      "source": [
        "# Classifier code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7mxhi2BD7or"
      },
      "source": [
        "\n",
        "Load individual subject data after pre-processing using TIMIT-MovieTrailer-AV-model-data-loader.ipynb.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvNU8q39GgZN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4219927a-894d-48b7-96b0-c37831529ea1"
      },
      "source": [
        "# choose 50 random indexes as test data from total 373 timit sentences. This set is limited to 373 because, for one subject, only 373 recording were present out of 380. \n",
        "import random\n",
        "test_list = random.sample(range(373), 115)\n",
        "train_list = [i for i in range(373) if i not in test_list]\n",
        "print(len(test_list), len(train_list))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "115 258\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mhKYbAlGEc1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "147cf514-caa1-4ec3-caf5-046ebccc80f9"
      },
      "source": [
        "#concatenate timit and movie files based on test and train subject split \n",
        "data_dir = '/content/drive/My Drive'\n",
        "train = ['MT0001','MT0002', 'MT0003','MT0004','MT0005','MT0006', 'MT0008','MT0009','MT0010', 'MT0011', 'MT0012', 'MT0013', 'MT0014', 'MT0015', 'MT0016', 'MT0017']\n",
        "\n",
        "for num,subject in enumerate(train):\n",
        "    timit_filename = data_dir + '/EEG_classifier/'+ subject + 'timit.npy'\n",
        "    movie_filename = data_dir + '/EEG_classifier/'+ subject + 'movie.npy'\n",
        "    print(num,subject)\n",
        "    if num == 0:\n",
        "        timit = np.load(timit_filename)\n",
        "        movie = np.load(movie_filename)\n",
        "        print(timit.shape)\n",
        "        train_timit = timit[train_list,:,:]\n",
        "        train_movie = movie[train_list,:,:]\n",
        "\n",
        "        test_timit = timit[test_list,:,:]\n",
        "        test_movie = movie[test_list,:,:]\n",
        "    else:\n",
        "        timit = np.load(timit_filename)\n",
        "        print(timit.shape)\n",
        "        train_timit = np.concatenate((train_timit, timit[train_list,:,:]), axis = 0)\n",
        "        movie = np.load(movie_filename)\n",
        "        train_movie = np.concatenate((train_movie, movie[train_list,:,:]), axis = 0)\n",
        "\n",
        "        test_timit = np.concatenate((test_timit, timit[test_list,:,:]), axis = 0)\n",
        "        test_movie = np.concatenate((test_movie, movie[test_list,:,:]), axis = 0)\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 MT0001\n",
            "(380, 64, 350)\n",
            "1 MT0002\n",
            "(380, 64, 350)\n",
            "2 MT0003\n",
            "(373, 64, 350)\n",
            "3 MT0004\n",
            "(380, 64, 350)\n",
            "4 MT0005\n",
            "(379, 64, 350)\n",
            "5 MT0006\n",
            "(379, 64, 350)\n",
            "6 MT0008\n",
            "(380, 64, 350)\n",
            "7 MT0009\n",
            "(379, 64, 350)\n",
            "8 MT0010\n",
            "(380, 64, 350)\n",
            "9 MT0011\n",
            "(380, 64, 350)\n",
            "10 MT0012\n",
            "(378, 64, 350)\n",
            "11 MT0013\n",
            "(380, 64, 350)\n",
            "12 MT0014\n",
            "(380, 64, 350)\n",
            "13 MT0015\n",
            "(379, 64, 350)\n",
            "14 MT0016\n",
            "(379, 64, 350)\n",
            "15 MT0017\n",
            "(378, 64, 350)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DG7oUgtrx9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8028274f-6f91-4d6b-84e0-dbc48df26da8"
      },
      "source": [
        "train_timit = np.reshape(train_timit,(train_timit.shape[0],train_timit.shape[2],train_timit.shape[1]))\n",
        "train_movie = np.reshape(train_movie,(train_movie.shape[0],train_movie.shape[2],train_movie.shape[1]))\n",
        "print(train_timit.shape, train_movie.shape)\n",
        "\n",
        "\n",
        "#y_train and y_test for timit and movie trailer\n",
        "train_shape = np.shape(train_timit)[0]\n",
        "y_train_timit = np.ones(train_shape)\n",
        "\n",
        "train_shape = np.shape(train_movie)[0]\n",
        "y_train_movie = np.zeros(train_shape)\n",
        "\n",
        "print(y_train_timit.shape)\n",
        "print(y_train_movie.shape)\n",
        "\n",
        "\n",
        "\n",
        "test_timit = np.reshape(test_timit,(test_timit.shape[0],test_timit.shape[2],test_timit.shape[1]))\n",
        "test_movie = np.reshape(test_movie,(test_movie.shape[0],test_movie.shape[2],test_movie.shape[1]))\n",
        "\n",
        "test_shape = np.shape(test_timit)[0]\n",
        "y_test_timit = np.ones(test_shape)\n",
        "\n",
        "test_shape = np.shape(test_movie)[0]\n",
        "y_test_movie = np.zeros(test_shape)\n",
        "print(test_timit.shape, test_movie.shape)\n",
        "print(y_test_timit.shape)\n",
        "print(y_test_movie.shape)\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4128, 350, 64) (4128, 350, 64)\n",
            "(4128,)\n",
            "(4128,)\n",
            "(1840, 350, 64) (1840, 350, 64)\n",
            "(1840,)\n",
            "(1840,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8MGK69grx9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2380f4b4-8ce1-401a-d16a-361263878318"
      },
      "source": [
        "#concatenate timit and movie EEG data\n",
        "\n",
        "\n",
        "train_X = np.concatenate((train_timit, train_movie), axis = 0)\n",
        "test_X = np.concatenate((test_timit, test_movie), axis = 0)\n",
        "\n",
        "train_y = np.concatenate((y_train_timit, y_train_movie))\n",
        "test_y = np.concatenate((y_test_timit, y_test_movie))\n",
        "\n",
        "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8256, 350, 64) (8256,) (3680, 350, 64) (3680,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kh0mHIADXs5",
        "outputId": "95123b3e-f398-428f-b94a-401ab2b3282d"
      },
      "source": [
        "#calculate % of test data\n",
        "print(test_X.shape[0]/(test_X.shape[0]+train_X.shape[0]))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.30831099195710454\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trfJw-Mhrx9l"
      },
      "source": [
        "#PCA the train and test data\n",
        "\n",
        "pca_case = False\n",
        "\n",
        "train_1 = train_X.shape[0]\n",
        "test_1 = test_X.shape[0]\n",
        "train_X = np.reshape(train_X, ((train_X.shape[0]*350,64)))\n",
        "test_X = np.reshape(test_X, ((test_X.shape[0]*350,64)))\n",
        "\n",
        "\n",
        "standard = StandardScaler()\n",
        "train_X = standard.fit_transform(train_X)\n",
        "test_X = standard.transform(test_X)\n",
        "\n",
        "n_components = 64\n",
        "if pca_case:\n",
        "  pca = decomposition.PCA(n_components= n_components)\n",
        "  pca.fit(train_X)\n",
        "  train_X_pca = pca.transform(train_X)\n",
        "  test_X_pca = pca.transform(test_X)\n",
        "\n",
        "\n",
        "  #reshape data into 3-D on PCA data\n",
        "  train_X_pca = np.reshape(train_X_pca, ((train_1,350,n_components)))\n",
        "  test_X_pca = np.reshape(test_X_pca, ((test_1,350,n_components)))\n",
        "\n",
        "else:\n",
        "  #reshape data into 3-D on non-pca data\n",
        "  train_X = np.reshape(train_X, ((train_1,350,n_components)))\n",
        "  test_X = np.reshape(test_X, ((test_1,350,n_components)))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iP3mgWmGA9kW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7569bf4b-6dee-4f88-a512-e96f95f905dc"
      },
      "source": [
        "#Print the distribution of 1s and 0s in train and test\n",
        "from collections import Counter\n",
        "print(Counter(test_y).keys()) \n",
        "print(Counter(test_y).values()) \n",
        "\n",
        "print(Counter(train_y).keys()) \n",
        "print(Counter(train_y).values())"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys([1.0, 0.0])\n",
            "dict_values([1840, 1840])\n",
            "dict_keys([1.0, 0.0])\n",
            "dict_values([4128, 4128])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSXr7NpzgbrH"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM, GRU, Dropout, BatchNormalization, Activation\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEE-3iywFnp2"
      },
      "source": [
        "In the below sections, we train 4 RNN models and Bayes model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUtm9NVOh8fT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bf095c5-2b10-4cb3-8e66-b380d7faae1e"
      },
      "source": [
        "## final experiments - pca - gru\n",
        "\n",
        "model = Sequential()\n",
        "model.add(GRU(100, input_shape=(train_X_pca.shape[1],train_X_pca.shape[2]), return_sequences=True))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(GRU(100, return_sequences=True))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(GRU(100, return_sequences=True))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(GRU(50))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "#model.build()\n",
        "print(model.summary())\n",
        "model.fit(train_X_pca, train_y, epochs=30, batch_size=64, verbose = 1)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_4 (GRU)                  (None, 350, 100)          49800     \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 350, 100)          400       \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 350, 100)          0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 350, 100)          0         \n",
            "_________________________________________________________________\n",
            "gru_5 (GRU)                  (None, 350, 100)          60600     \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 350, 100)          400       \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 350, 100)          0         \n",
            "_________________________________________________________________\n",
            "gru_6 (GRU)                  (None, 350, 100)          60600     \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 350, 100)          400       \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 350, 100)          0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 350, 100)          0         \n",
            "_________________________________________________________________\n",
            "gru_7 (GRU)                  (None, 50)                22800     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 195,051\n",
            "Trainable params: 194,451\n",
            "Non-trainable params: 600\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/30\n",
            "129/129 [==============================] - 8s 65ms/step - loss: 0.6854 - accuracy: 0.5687\n",
            "Epoch 2/30\n",
            "129/129 [==============================] - 8s 65ms/step - loss: 0.6458 - accuracy: 0.6267\n",
            "Epoch 3/30\n",
            "129/129 [==============================] - 8s 66ms/step - loss: 0.5984 - accuracy: 0.6778\n",
            "Epoch 4/30\n",
            "129/129 [==============================] - 8s 66ms/step - loss: 0.4628 - accuracy: 0.7733\n",
            "Epoch 5/30\n",
            "129/129 [==============================] - 8s 66ms/step - loss: 0.2660 - accuracy: 0.8894\n",
            "Epoch 6/30\n",
            "129/129 [==============================] - 8s 66ms/step - loss: 0.1813 - accuracy: 0.9306\n",
            "Epoch 7/30\n",
            "129/129 [==============================] - 8s 64ms/step - loss: 0.1424 - accuracy: 0.9444\n",
            "Epoch 8/30\n",
            "129/129 [==============================] - 8s 64ms/step - loss: 0.1196 - accuracy: 0.9560\n",
            "Epoch 9/30\n",
            "129/129 [==============================] - 8s 65ms/step - loss: 0.1045 - accuracy: 0.9585\n",
            "Epoch 10/30\n",
            "129/129 [==============================] - 8s 64ms/step - loss: 0.0878 - accuracy: 0.9666\n",
            "Epoch 11/30\n",
            "129/129 [==============================] - 8s 65ms/step - loss: 0.0901 - accuracy: 0.9660\n",
            "Epoch 12/30\n",
            "129/129 [==============================] - 8s 65ms/step - loss: 0.0684 - accuracy: 0.9755\n",
            "Epoch 13/30\n",
            "129/129 [==============================] - 8s 65ms/step - loss: 0.0675 - accuracy: 0.9750\n",
            "Epoch 14/30\n",
            "129/129 [==============================] - 8s 65ms/step - loss: 0.0524 - accuracy: 0.9815\n",
            "Epoch 15/30\n",
            "129/129 [==============================] - 8s 64ms/step - loss: 0.0645 - accuracy: 0.9754\n",
            "Epoch 16/30\n",
            "129/129 [==============================] - 8s 65ms/step - loss: 0.0460 - accuracy: 0.9855\n",
            "Epoch 17/30\n",
            "129/129 [==============================] - 8s 65ms/step - loss: 0.0540 - accuracy: 0.9813\n",
            "Epoch 18/30\n",
            "129/129 [==============================] - 8s 64ms/step - loss: 0.0449 - accuracy: 0.9834\n",
            "Epoch 19/30\n",
            "129/129 [==============================] - 8s 65ms/step - loss: 0.0387 - accuracy: 0.9869\n",
            "Epoch 20/30\n",
            "129/129 [==============================] - 8s 65ms/step - loss: 0.0480 - accuracy: 0.9838\n",
            "Epoch 21/30\n",
            "129/129 [==============================] - 8s 65ms/step - loss: 0.0322 - accuracy: 0.9879\n",
            "Epoch 22/30\n",
            "129/129 [==============================] - 8s 65ms/step - loss: 0.0293 - accuracy: 0.9907\n",
            "Epoch 23/30\n",
            "129/129 [==============================] - 8s 65ms/step - loss: 0.0326 - accuracy: 0.9870\n",
            "Epoch 24/30\n",
            "129/129 [==============================] - 8s 65ms/step - loss: 0.0336 - accuracy: 0.9876\n",
            "Epoch 25/30\n",
            "129/129 [==============================] - 8s 65ms/step - loss: 0.0259 - accuracy: 0.9918\n",
            "Epoch 26/30\n",
            "129/129 [==============================] - 8s 65ms/step - loss: 0.0339 - accuracy: 0.9887\n",
            "Epoch 27/30\n",
            "129/129 [==============================] - 8s 65ms/step - loss: 0.0269 - accuracy: 0.9903\n",
            "Epoch 28/30\n",
            "129/129 [==============================] - 8s 65ms/step - loss: 0.0194 - accuracy: 0.9932\n",
            "Epoch 29/30\n",
            "129/129 [==============================] - 8s 66ms/step - loss: 0.0297 - accuracy: 0.9891\n",
            "Epoch 30/30\n",
            "129/129 [==============================] - 8s 66ms/step - loss: 0.0243 - accuracy: 0.9920\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff1aa8b7ef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-znHnvNiiAQ4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3c4590b-8206-450f-bbb7-5a2535c65ab3"
      },
      "source": [
        "# Final evaluation of the model\n",
        "scores = model.evaluate(test_X_pca, test_y, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 97.55%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2K40OTwMrf0W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72826b27-d5ea-4ac0-995f-022ce3fa15ea"
      },
      "source": [
        "## final experiments - pca - LSTM\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(100, input_shape=(train_X_pca.shape[1],train_X_pca.shape[2]), return_sequences=True))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(100, return_sequences=True))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(LSTM(100, return_sequences=True))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(50))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "#model.build()\n",
        "print(model.summary())\n",
        "model.fit(train_X_pca, train_y, epochs=30, batch_size=64, verbose = 1)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_4 (LSTM)                (None, 350, 100)          66000     \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 350, 100)          400       \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 350, 100)          0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 350, 100)          0         \n",
            "_________________________________________________________________\n",
            "lstm_5 (LSTM)                (None, 350, 100)          80400     \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 350, 100)          400       \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 350, 100)          0         \n",
            "_________________________________________________________________\n",
            "lstm_6 (LSTM)                (None, 350, 100)          80400     \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 350, 100)          400       \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 350, 100)          0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 350, 100)          0         \n",
            "_________________________________________________________________\n",
            "lstm_7 (LSTM)                (None, 50)                30200     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 258,251\n",
            "Trainable params: 257,651\n",
            "Non-trainable params: 600\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/30\n",
            "  2/129 [..............................] - ETA: 7s - loss: 0.7269 - accuracy: 0.4609WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0409s vs `on_train_batch_end` time: 0.0630s). Check your callbacks.\n",
            "129/129 [==============================] - 10s 80ms/step - loss: 0.6673 - accuracy: 0.5952\n",
            "Epoch 2/30\n",
            "129/129 [==============================] - 10s 81ms/step - loss: 0.6268 - accuracy: 0.6462\n",
            "Epoch 3/30\n",
            "129/129 [==============================] - 10s 81ms/step - loss: 0.6021 - accuracy: 0.6692\n",
            "Epoch 4/30\n",
            "129/129 [==============================] - 10s 80ms/step - loss: 0.5799 - accuracy: 0.6903\n",
            "Epoch 5/30\n",
            "129/129 [==============================] - 10s 80ms/step - loss: 0.5391 - accuracy: 0.7257\n",
            "Epoch 6/30\n",
            "129/129 [==============================] - 10s 80ms/step - loss: 0.5183 - accuracy: 0.7436\n",
            "Epoch 7/30\n",
            "129/129 [==============================] - 10s 81ms/step - loss: 0.4726 - accuracy: 0.7672\n",
            "Epoch 8/30\n",
            "129/129 [==============================] - 10s 80ms/step - loss: 0.4187 - accuracy: 0.8102\n",
            "Epoch 9/30\n",
            "129/129 [==============================] - 10s 80ms/step - loss: 0.3927 - accuracy: 0.8233\n",
            "Epoch 10/30\n",
            "129/129 [==============================] - 10s 80ms/step - loss: 0.3520 - accuracy: 0.8448\n",
            "Epoch 11/30\n",
            "129/129 [==============================] - 10s 80ms/step - loss: 0.2846 - accuracy: 0.8815\n",
            "Epoch 12/30\n",
            "129/129 [==============================] - 10s 79ms/step - loss: 0.2350 - accuracy: 0.9046\n",
            "Epoch 13/30\n",
            "129/129 [==============================] - 10s 79ms/step - loss: 0.1821 - accuracy: 0.9264\n",
            "Epoch 14/30\n",
            "129/129 [==============================] - 10s 79ms/step - loss: 0.1480 - accuracy: 0.9397\n",
            "Epoch 15/30\n",
            "129/129 [==============================] - 10s 79ms/step - loss: 0.1330 - accuracy: 0.9491\n",
            "Epoch 16/30\n",
            "129/129 [==============================] - 10s 79ms/step - loss: 0.1061 - accuracy: 0.9571\n",
            "Epoch 17/30\n",
            "129/129 [==============================] - 10s 80ms/step - loss: 0.0995 - accuracy: 0.9604\n",
            "Epoch 18/30\n",
            "129/129 [==============================] - 10s 80ms/step - loss: 0.0836 - accuracy: 0.9713\n",
            "Epoch 19/30\n",
            "129/129 [==============================] - 10s 80ms/step - loss: 0.0799 - accuracy: 0.9715\n",
            "Epoch 20/30\n",
            "129/129 [==============================] - 10s 80ms/step - loss: 0.0703 - accuracy: 0.9763\n",
            "Epoch 21/30\n",
            "129/129 [==============================] - 10s 79ms/step - loss: 0.0581 - accuracy: 0.9784\n",
            "Epoch 22/30\n",
            "129/129 [==============================] - 10s 80ms/step - loss: 0.0518 - accuracy: 0.9810\n",
            "Epoch 23/30\n",
            "129/129 [==============================] - 10s 80ms/step - loss: 0.0511 - accuracy: 0.9813\n",
            "Epoch 24/30\n",
            "129/129 [==============================] - 10s 81ms/step - loss: 0.0365 - accuracy: 0.9879\n",
            "Epoch 25/30\n",
            "129/129 [==============================] - 10s 80ms/step - loss: 0.0437 - accuracy: 0.9846\n",
            "Epoch 26/30\n",
            "129/129 [==============================] - 10s 81ms/step - loss: 0.0348 - accuracy: 0.9876\n",
            "Epoch 27/30\n",
            "129/129 [==============================] - 10s 80ms/step - loss: 0.0435 - accuracy: 0.9849\n",
            "Epoch 28/30\n",
            "129/129 [==============================] - 10s 80ms/step - loss: 0.0363 - accuracy: 0.9879\n",
            "Epoch 29/30\n",
            "129/129 [==============================] - 10s 79ms/step - loss: 0.0281 - accuracy: 0.9912\n",
            "Epoch 30/30\n",
            "129/129 [==============================] - 10s 80ms/step - loss: 0.0278 - accuracy: 0.9912\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff1a6ff9f28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYEWhvE_rg9D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c2c519a-2567-43e7-80ac-f17c45d1d7e8"
      },
      "source": [
        "# Final evaluation of the model\n",
        "scores = model.evaluate(test_X_pca, test_y, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 95.52%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvpiF6MsgdIr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "376a5859-f939-43a0-ffa7-6c7a3b9ff8df"
      },
      "source": [
        "## final experiments - no pca - gru\n",
        "\n",
        "model = Sequential()\n",
        "model.add(GRU(100, input_shape=(train_X.shape[1],train_X.shape[2]), return_sequences=True))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(GRU(100, return_sequences=True))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(GRU(100, return_sequences=True))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(GRU(50))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "#model.build()\n",
        "print(model.summary())\n",
        "model.fit(train_X, train_y, epochs=30, batch_size=64, verbose = 1)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru (GRU)                    (None, 350, 100)          49800     \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 350, 100)          400       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 350, 100)          0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 350, 100)          0         \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (None, 350, 100)          60600     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 350, 100)          400       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 350, 100)          0         \n",
            "_________________________________________________________________\n",
            "gru_2 (GRU)                  (None, 350, 100)          60600     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 350, 100)          400       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 350, 100)          0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 350, 100)          0         \n",
            "_________________________________________________________________\n",
            "gru_3 (GRU)                  (None, 50)                22800     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 195,051\n",
            "Trainable params: 194,451\n",
            "Non-trainable params: 600\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/30\n",
            "129/129 [==============================] - 8s 65ms/step - loss: 0.6875 - accuracy: 0.5620\n",
            "Epoch 2/30\n",
            "129/129 [==============================] - 8s 65ms/step - loss: 0.6477 - accuracy: 0.6177\n",
            "Epoch 3/30\n",
            "129/129 [==============================] - 8s 65ms/step - loss: 0.5869 - accuracy: 0.6865\n",
            "Epoch 4/30\n",
            "129/129 [==============================] - 8s 66ms/step - loss: 0.3707 - accuracy: 0.8328\n",
            "Epoch 5/30\n",
            "129/129 [==============================] - 8s 65ms/step - loss: 0.2078 - accuracy: 0.9190\n",
            "Epoch 6/30\n",
            "129/129 [==============================] - 8s 65ms/step - loss: 0.1666 - accuracy: 0.9334\n",
            "Epoch 7/30\n",
            "129/129 [==============================] - 8s 65ms/step - loss: 0.1307 - accuracy: 0.9509\n",
            "Epoch 8/30\n",
            "129/129 [==============================] - 8s 66ms/step - loss: 0.1143 - accuracy: 0.9575\n",
            "Epoch 9/30\n",
            "129/129 [==============================] - 8s 65ms/step - loss: 0.1126 - accuracy: 0.9566\n",
            "Epoch 10/30\n",
            "129/129 [==============================] - 9s 66ms/step - loss: 0.0917 - accuracy: 0.9668\n",
            "Epoch 11/30\n",
            "129/129 [==============================] - 8s 65ms/step - loss: 0.0806 - accuracy: 0.9708\n",
            "Epoch 12/30\n",
            "129/129 [==============================] - 8s 66ms/step - loss: 0.0735 - accuracy: 0.9715\n",
            "Epoch 13/30\n",
            "129/129 [==============================] - 9s 66ms/step - loss: 0.0653 - accuracy: 0.9761\n",
            "Epoch 14/30\n",
            "129/129 [==============================] - 8s 66ms/step - loss: 0.0576 - accuracy: 0.9789\n",
            "Epoch 15/30\n",
            "129/129 [==============================] - 8s 66ms/step - loss: 0.0591 - accuracy: 0.9778\n",
            "Epoch 16/30\n",
            "129/129 [==============================] - 9s 66ms/step - loss: 0.0509 - accuracy: 0.9805\n",
            "Epoch 17/30\n",
            "129/129 [==============================] - 8s 66ms/step - loss: 0.0467 - accuracy: 0.9839\n",
            "Epoch 18/30\n",
            "129/129 [==============================] - 8s 65ms/step - loss: 0.0416 - accuracy: 0.9834\n",
            "Epoch 19/30\n",
            "129/129 [==============================] - 8s 65ms/step - loss: 0.0329 - accuracy: 0.9880\n",
            "Epoch 20/30\n",
            "129/129 [==============================] - 8s 65ms/step - loss: 0.0343 - accuracy: 0.9868\n",
            "Epoch 21/30\n",
            "129/129 [==============================] - 8s 65ms/step - loss: 0.0409 - accuracy: 0.9867\n",
            "Epoch 22/30\n",
            "129/129 [==============================] - 8s 66ms/step - loss: 0.0273 - accuracy: 0.9907\n",
            "Epoch 23/30\n",
            "129/129 [==============================] - 9s 66ms/step - loss: 0.0368 - accuracy: 0.9853\n",
            "Epoch 24/30\n",
            "129/129 [==============================] - 9s 66ms/step - loss: 0.0322 - accuracy: 0.9880\n",
            "Epoch 25/30\n",
            "129/129 [==============================] - 9s 66ms/step - loss: 0.0274 - accuracy: 0.9912\n",
            "Epoch 26/30\n",
            "129/129 [==============================] - 8s 66ms/step - loss: 0.0310 - accuracy: 0.9883\n",
            "Epoch 27/30\n",
            "129/129 [==============================] - 8s 66ms/step - loss: 0.0292 - accuracy: 0.9904\n",
            "Epoch 28/30\n",
            "129/129 [==============================] - 9s 66ms/step - loss: 0.0296 - accuracy: 0.9898\n",
            "Epoch 29/30\n",
            "129/129 [==============================] - 8s 66ms/step - loss: 0.0250 - accuracy: 0.9912\n",
            "Epoch 30/30\n",
            "129/129 [==============================] - 9s 66ms/step - loss: 0.0261 - accuracy: 0.9908\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff2ed47b1d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVTlaLXigkJL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18d148f3-fa99-4492-8b7e-32a856055b4a"
      },
      "source": [
        "# Final evaluation of the model\n",
        "scores = model.evaluate(test_X, test_y, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 98.15%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zhp-SEldJAB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5115593d-0ea7-4c90-8636-3a97576084e6"
      },
      "source": [
        "## final experiments - no pca  - LSTM\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(100, input_shape=(train_X.shape[1],train_X.shape[2]), return_sequences=True))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(100, return_sequences=True))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(LSTM(100, return_sequences=True))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(50))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "#model.build()\n",
        "print(model.summary())\n",
        "model.fit(train_X, train_y, epochs=30, batch_size=64, verbose = 1)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 350, 100)          66000     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 350, 100)          400       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 350, 100)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 350, 100)          0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 350, 100)          80400     \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 350, 100)          400       \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 350, 100)          0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 350, 100)          80400     \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 350, 100)          400       \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 350, 100)          0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 350, 100)          0         \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 50)                30200     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 258,251\n",
            "Trainable params: 257,651\n",
            "Non-trainable params: 600\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/30\n",
            "129/129 [==============================] - 10s 80ms/step - loss: 0.6651 - accuracy: 0.5902\n",
            "Epoch 2/30\n",
            "129/129 [==============================] - 10s 80ms/step - loss: 0.6237 - accuracy: 0.6533\n",
            "Epoch 3/30\n",
            "129/129 [==============================] - 10s 80ms/step - loss: 0.5849 - accuracy: 0.6888\n",
            "Epoch 4/30\n",
            "129/129 [==============================] - 10s 80ms/step - loss: 0.5662 - accuracy: 0.7083\n",
            "Epoch 5/30\n",
            "129/129 [==============================] - 10s 80ms/step - loss: 0.5141 - accuracy: 0.7426\n",
            "Epoch 6/30\n",
            "129/129 [==============================] - 10s 80ms/step - loss: 0.5131 - accuracy: 0.7420\n",
            "Epoch 7/30\n",
            "129/129 [==============================] - 10s 80ms/step - loss: 0.4483 - accuracy: 0.7906\n",
            "Epoch 8/30\n",
            "129/129 [==============================] - 10s 80ms/step - loss: 0.3928 - accuracy: 0.8267\n",
            "Epoch 9/30\n",
            "129/129 [==============================] - 10s 80ms/step - loss: 0.3676 - accuracy: 0.8390\n",
            "Epoch 10/30\n",
            "129/129 [==============================] - 10s 80ms/step - loss: 0.3260 - accuracy: 0.8617\n",
            "Epoch 11/30\n",
            "129/129 [==============================] - 10s 80ms/step - loss: 0.2836 - accuracy: 0.8805\n",
            "Epoch 12/30\n",
            "129/129 [==============================] - 10s 80ms/step - loss: 0.2594 - accuracy: 0.8903\n",
            "Epoch 13/30\n",
            "129/129 [==============================] - 10s 80ms/step - loss: 0.2123 - accuracy: 0.9161\n",
            "Epoch 14/30\n",
            "129/129 [==============================] - 10s 80ms/step - loss: 0.1602 - accuracy: 0.9375\n",
            "Epoch 15/30\n",
            "129/129 [==============================] - 10s 80ms/step - loss: 0.1188 - accuracy: 0.9557\n",
            "Epoch 16/30\n",
            "129/129 [==============================] - 10s 80ms/step - loss: 0.1012 - accuracy: 0.9628\n",
            "Epoch 17/30\n",
            "129/129 [==============================] - 10s 80ms/step - loss: 0.0834 - accuracy: 0.9674\n",
            "Epoch 18/30\n",
            "129/129 [==============================] - 10s 80ms/step - loss: 0.0697 - accuracy: 0.9749\n",
            "Epoch 19/30\n",
            "129/129 [==============================] - 10s 80ms/step - loss: 0.0710 - accuracy: 0.9724\n",
            "Epoch 20/30\n",
            "129/129 [==============================] - 10s 79ms/step - loss: 0.0688 - accuracy: 0.9741\n",
            "Epoch 21/30\n",
            "129/129 [==============================] - 10s 80ms/step - loss: 0.0580 - accuracy: 0.9809\n",
            "Epoch 22/30\n",
            "129/129 [==============================] - 10s 80ms/step - loss: 0.0604 - accuracy: 0.9788\n",
            "Epoch 23/30\n",
            "129/129 [==============================] - 10s 80ms/step - loss: 0.0404 - accuracy: 0.9858\n",
            "Epoch 24/30\n",
            "129/129 [==============================] - 10s 80ms/step - loss: 0.0749 - accuracy: 0.9727\n",
            "Epoch 25/30\n",
            "129/129 [==============================] - 10s 80ms/step - loss: 0.0431 - accuracy: 0.9851\n",
            "Epoch 26/30\n",
            "129/129 [==============================] - 10s 80ms/step - loss: 0.0280 - accuracy: 0.9910\n",
            "Epoch 27/30\n",
            "129/129 [==============================] - 10s 80ms/step - loss: 0.0439 - accuracy: 0.9846\n",
            "Epoch 28/30\n",
            "129/129 [==============================] - 10s 80ms/step - loss: 0.0339 - accuracy: 0.9881\n",
            "Epoch 29/30\n",
            "129/129 [==============================] - 10s 80ms/step - loss: 0.0266 - accuracy: 0.9912\n",
            "Epoch 30/30\n",
            "129/129 [==============================] - 10s 80ms/step - loss: 0.0320 - accuracy: 0.9891\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff2ea31c630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeAaoKc0doxO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31e68fea-4173-41d0-b2cc-f0cd0f5c620b"
      },
      "source": [
        "# Final evaluation of the model\n",
        "scores = model.evaluate(test_X, test_y, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 94.48%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLX3rKa_GT2-"
      },
      "source": [
        "**Bayes Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Fb-VXPTGVyo",
        "outputId": "62a9fb64-08a5-42f9-8931-9faae7efc69c"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "#reshape into 2-D data\n",
        "train_X = np.reshape(train_X, ((train_X.shape[0]*350,64)))\n",
        "test_X = np.reshape(test_X, ((test_X.shape[0]*350,64)))\n",
        "\n",
        "#naive bayes filling the label\n",
        "train_l_ = np.zeros((train_X.shape[0]))\n",
        "test_l_ = np.zeros((test_X.shape[0]))\n",
        "\n",
        "for i in range(train_y.shape[0]):\n",
        "  train_l_[i*350:i*350+350] = train_y[i]\n",
        "\n",
        "for i in range(test_y.shape[0]):\n",
        "  test_l_[i*350:i*350+350] = test_y[i]\n",
        "\n",
        "\n",
        "#without pca - Gaussian Naive Bayes model\n",
        "gnb = GaussianNB()\n",
        "y_pred = gnb.fit(train_X, train_l_).predict(test_X)\n",
        "accuracy_score(y_pred, test_l_)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.49060326086956524"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0002GNBMhr-a"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}