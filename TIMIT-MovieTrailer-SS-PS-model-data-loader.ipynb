{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@author: Madhumitha Sakthi, Maansi Desai\n",
    "\n",
    "This code processes the .fif EEG files and partitions them based on .wav file name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import mne # For loading EEG data\n",
    "import numpy as np\n",
    "from praatio import tgio # For importing textgrids with word level transcriptions\n",
    "import glob \n",
    "import os\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import decomposition\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define subject\n",
    "subjects = ['MT0001','MT0002','MT0003','MT0004','MT0005','MT0006', 'MT0008','MT0009', 'MT0010', 'MT0011', 'MT0012', 'MT0013', 'MT0014', 'MT0015', 'MT0016', 'MT0017']\n",
    "\n",
    "data_dir = 'path/to/original/files'  #.fif files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_raw_EEG(subject, data_dir):\n",
    "    '''\n",
    "    Load the preprocessed EEG (post-ICA), removing bad time points if they exist\n",
    "    Input : \n",
    "        subject [str] : the subject ID (e.g. 'MT0001')\n",
    "        data_dir [str] : the path to your data\n",
    "    Output : \n",
    "        raw [mne Raw object] : the data structure containing the EEG for this participant\n",
    "    '''\n",
    "    eeg_file = '%s/%s_postICA_rejected.fif'%(data_dir, subject)\n",
    "    raw = mne.io.read_raw_fif(eeg_file, preload=True)\n",
    "    \n",
    "\n",
    "    # Print which are the bad channels, but don't get rid of them yet...\n",
    "    raw.pick_types(eeg=True, meg=False, exclude=[])\n",
    "    bad_chans = raw.info['bads']\n",
    "    print(\"Bad channels are: \")\n",
    "    print(bad_chans)\n",
    "\n",
    "    # Get onset and duration of the bad segments in samples\n",
    "    bad_time_onsets = raw.annotations.onset * raw.info['sfreq']\n",
    "    bad_time_durs = raw.annotations.duration * raw.info['sfreq']\n",
    "\n",
    "    print(raw._data.shape)\n",
    "\n",
    "    # Set the bad time points to zero\n",
    "    for bad_idx, bad_time in enumerate(bad_time_onsets):\n",
    "        raw._data[:,np.int(bad_time):np.int(bad_time+bad_time_durs[bad_idx])] = 0\n",
    "    \n",
    "    return raw\n",
    "\n",
    "# Load event file and get times of TIMIT sentences or MTs\n",
    "def load_event_file(subject, data_dir, fs=128, event_file_name='TIMIT'):\n",
    "    '''\n",
    "    Get the TIMIT or MovieTrailers event file with start and stop times relative to the EEG start time for a \n",
    "    particular subject. This event file has one row per TIMIT sentence or one row per MovieTrailer, depending\n",
    "    on which stimulus is chosen.\n",
    "    Inputs:\n",
    "        subject [str] : subject ID (e.g. 'MT0001')\n",
    "        data_dir [str] : path to your data and event files\n",
    "        fs [int] : the sampling frequency for returning the samples\n",
    "        event_file_name [str] : 'TIMIT' or 'MovieTrailers' -- which event file to load\n",
    "    Output:\n",
    "        evs : the offset and onset samples (assuming [fs] sampling frequency)\n",
    "        wav_id : the name of the .wav that corresponds to ev\n",
    "    '''\n",
    "    if event_file_name=='TIMIT':\n",
    "        event_file = '%s/%s_TIMIT_all_events.txt'%(data_dir, subject) #timit\n",
    "        \n",
    "    elif event_file_name=='MOVIE':\n",
    "        event_file = '%s/%s_MovieTrailers_events.txt'%(data_dir, subject) #movie trailer\n",
    "    \n",
    "    else:\n",
    "        print('Input is unrecognizable.')\n",
    "   \n",
    "    # Load the columns with the times    \n",
    "    evs = np.loadtxt(event_file, dtype='f', usecols = (0, 1, 2))\n",
    "    evs[:,:2] = evs[:,:2]*fs #128 is the downsampled frequency from EEG data\n",
    "    evs = evs.astype(np.int) #this takes into account onset and offset times\n",
    "    wav_id = np.loadtxt(event_file, dtype='<U', usecols = 3) #name of .wav filename\n",
    "    \n",
    "    return evs, wav_id\n",
    "\n",
    "\n",
    "#function to epoch your data\n",
    "def get_event_epoch(raw, evs, event_id, wav_id, bef_aft=[-0.5,0.5], baseline = None, reject_by_annotation=False):\n",
    "\n",
    "    '''\n",
    "    Epoch preprocessed EEG (post-ICA). Will epoch based on length of TIMIT sentence specified in event file\n",
    "    Input : \n",
    "        raw [mne Raw object] : created from load_raw_EEG for given participant\n",
    "        evs [numpy array] : the path to your data with all event onset information from textfiles. Also contains event_id in last column\n",
    "        event_id [int]: last column in evs \n",
    "        bef_aft: hard coded to give epochs of neural data 0.5 seconds before and after\n",
    "    Output : \n",
    "        raw [mne Raw object] : the data structure containing the EEG for this participant\n",
    "    '''\n",
    "    \n",
    "    # Get duration information\n",
    "    max_samp_dur = np.max(evs[(np.where(evs[:,2] == event_id)),1]-evs[(np.where(evs[:,2] == event_id)),0])\n",
    "    trial_dur = max_samp_dur/raw.info['sfreq']\n",
    "    \n",
    "    epochs = mne.Epochs(raw, evs, event_id=[event_id], tmin=bef_aft[0], tmax=trial_dur+bef_aft[1], baseline=baseline,\n",
    "                        reject_by_annotation=reject_by_annotation)\n",
    "    ep = epochs.get_data()\n",
    "    times = epochs.times\n",
    "    wav_title = wav_id[np.where(evs[:,2] == event_id)]\n",
    "        \n",
    "    return ep, times, wav_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterate through each subject and save data individually\n",
    "\n",
    "for subject in subjects:\n",
    "    sub_dir = data_dir+'/'+ subject\n",
    "    print(\"sub_dir:\", sub_dir)\n",
    "    raw = load_raw_EEG(subject, sub_dir)\n",
    "    raw.interpolate_bads() # Interpolate the bad channels \n",
    "    raw.plot_psd()\n",
    "\n",
    "    ch_names = raw.info['ch_names']\n",
    "\n",
    "    # Get the sentence event times.\n",
    "    # evs contains the start sample, stop sample, and unique number identifying the sentence\n",
    "    # These unique names can be matched up to specific wav files in Stimuli/wavs and Stimuli/Textgrids\n",
    "    # with wav_id\n",
    "    \n",
    "    #load timit data\n",
    "    evs_timit, wav_id_timit = load_event_file(subject, sub_dir, fs=128, event_file_name='TIMIT')\n",
    "    \n",
    "    #load movie data\n",
    "    evs_movie, wav_id_movie = load_event_file(subject, sub_dir, fs=128, event_file_name='MOVIE')\n",
    "    \n",
    "    timit_total = 0\n",
    "    movie_total = 0\n",
    "    timit_filename = data_dir + '/EEG_LSTM/'+ subject + 'timit/'#.npy'\n",
    "    movie_filename = data_dir + '/EEG_LSTM/'+ subject + 'movie/'#.npy'\n",
    "    os.mkdir(timit_filename)\n",
    "    print(\"mkdir\", timit_filename)\n",
    "    os.mkdir(movie_filename)\n",
    "    print(\"mkdir\", movie_filename)\n",
    "    \n",
    "    \n",
    "    #process timit sentences\n",
    "    event_ids = evs_timit[:,2]\n",
    "    print(event_ids.shape)\n",
    "    event_ids = np.unique(event_ids) #extract unique sentences from event_files\n",
    "    print(event_ids)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    #print(event_ids.shape[0])\n",
    "    for x in range(event_ids.shape[0]):\n",
    "        event_id = event_ids[x]\n",
    "        \n",
    "        #print(\"event id:\", event_id)\n",
    "        ep, times, wav_title = get_event_epoch(raw, evs_timit, event_id, wav_id_timit, bef_aft=[-0.5,1], baseline = (None, 0), reject_by_annotation=False)\n",
    "        #print(\"ep shape:\", ep.shape)\n",
    "        timit_file = timit_filename + wav_title[0][:-4] + '.npy' \n",
    "        if ep.shape[0] >= 1:\n",
    "            ep = ep[[0]]\n",
    "            print(\"ep shape:\", ep.shape, wav_title[0][:-4])\n",
    "            \n",
    "            timit_total = timit_total + 1\n",
    "            np.save(timit_file, ep)\n",
    "\n",
    "    print(timit_total)\n",
    "    \n",
    "    \n",
    "    #process movie sentences\n",
    "    event_ids = evs_movie[:,2]\n",
    "    #print(event_ids.shape)\n",
    "    event_ids = np.unique(event_ids) #extract unique sentences from event_files\n",
    "    #print(event_ids)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    #print(event_ids.shape[0])\n",
    "    for x in range(event_ids.shape[0]):\n",
    "        event_id = event_ids[x]\n",
    "        \n",
    "        #print(\"event id:\", event_id)\n",
    "        ep, times, wav_title = get_event_epoch(raw, evs_movie, event_id, wav_id_movie, bef_aft=[-0.5,1], baseline = (None, 0), reject_by_annotation=False)\n",
    "        #print(\"ep shape:\", ep.shape)\n",
    "        movie_file = movie_filename + wav_title[0][:-4]\n",
    "        if ep.shape[0] >= 1:\n",
    "            ep = ep[[0]]\n",
    "            movie_total = movie_total + 1\n",
    "            np.save(movie_file, ep)\n",
    "    #print(movie_total)\n",
    "    \n",
    "            \n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
